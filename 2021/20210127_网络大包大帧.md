http://blog.nsfocus.net/network-packets-analysis-nic-offload/

今天发现frame远远大于MTU的1500，frame达到60K+，但这个不是物理链路上就有限制的么？ 为什么会超出。原因是和两个参数有关系：`gto`和`tso`

#### MTU 与IP分片
当IP包大于这个值是，IP包需要分成多个IP分片，使得每个分片的大小满足MTU的大小限制。除了对payload进行分片之外，原先IP包的包头也要进行处理。
把原先的ip头的 identification 复制一下， 分片中的设置DF位等等。

#### MSS
最大分段长度，这个是TCP层的控制，这个一般和MTU有关，导致TCP报文分装成IP报文时，一般不会超过MTU的大小。

#### TOE 和 网卡的offload
为了解决性能问题，就产生了TOE技术（TCP offload engine），将TCP连接过程中的相关计算工作转移到专用硬件上（比如网卡），从而释放CPU资源。从2012年开始，这项技术开始在普通用户的网卡上应用。
本文所描述的offload特性，主要是指将原本在协议栈中进行的IP分片、TCP分段、重组、checksum校验等操作，转移到网卡硬件中进行，降低系统CPU的消耗，提高处理性能。

#### TSO
从名字来看很直观，就是把tcp分段的过程转移到网卡中进行。当网卡支持TSO机制时，可以直接把不超过滑动窗口大小的payload下传给协议栈，即使数据长度大于MSS，也不会在TCP层进行分段，同样也不会进行IP分片，而是直接传送给网卡驱动，由网卡驱动进行tcp分段操作，并执行checksum计算和包头、帧头的生成工作。

#### GTO
相对于TSO和UFO，GSO机制是针对所有协议设计的，更为通用。同时，与TSO、UFO不同的是，GSO主要依靠软件的方式实现，对于网卡硬件没有过多的要求。其基本思想就是把数据分片的操作尽可能的向底层推迟直到数据发送给网卡驱动之前，并先检查网卡是否支持TSO或UFO机制，如果支持就直接把数据发送给网卡，否则的话再进行分片后发送给网卡，以此来保证最少次数的协议栈处理，提高数据传输和处理的效率。

#### 网卡offload模式的设置

#### 网卡Offload技术给网络数据包分析带来的影响
目前常用的抓包工具大部分都是从协议栈中（如数据链路层）捕获数据包，而网卡的offload特性会将数据包的分片、重组等工作转移到协议栈以下的硬件层面进行，因此在开启TSO、GRO等机制的情况下，我们使用tcpdump、wireshark等工具抓取到的数据包往往不能真实反应链路上实际的数据帧，给网络流量特征的分析造成不利影响。

在某些情况下，例如分片攻击等攻击方式，甚至可能会因为网卡设备的offload机制处理，而规避防火墙、IDS以及人工的检查。针对这些情况，可以选择关闭网卡offload的相关选项，或者在链路的其他节点进行抓包
